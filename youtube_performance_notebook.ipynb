{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb80085",
   "metadata": {},
   "source": [
    "# Unlocking YouTube Channel Performance Secrets — Notebook\n",
    "\n",
    "This notebook follows the project described in the provided PDF to analyze YouTube channel performance and build a predictive model for **Estimated Revenue (USD)**. It includes import, cleaning, feature engineering, visualization, modeling, evaluation, and model export steps. The PDF used as reference: see file citation in the chat. fileciteturn1file0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de166d4a",
   "metadata": {},
   "source": [
    "**Description:** Import necessary libraries for data handling, visualization, modeling and saving artifacts. This matches the PDF's recommended stack. fileciteturn1file0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1827070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Load dataset\n",
    "# Update this path to your CSV file downloaded from the link in the PDF\n",
    "data_path = 'youtube_channel_real_performance_analytics.csv'\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print('Loaded data with shape:', df.shape)\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print('File not found. Please download the dataset from the PDF link and set data_path accordingly.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef268b",
   "metadata": {},
   "source": [
    "**Description:** Load dataset (the PDF shows an example Kaggle CSV). If you haven't downloaded it yet, use the Google Drive link provided in the PDF. fileciteturn1file0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Basic info and missing values\n",
    "if 'df' in globals():\n",
    "    print(df.info())\n",
    "    print('\\nMissing values per column:')\n",
    "    print(df.isnull().sum().sort_values(ascending=False).head(30))\n",
    "    display(df.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2680571",
   "metadata": {},
   "source": [
    "**Description:** Inspect data types, missing values and summary statistics to plan cleaning. The PDF indicates there are 70 columns and no nulls in the sample, but always check your copy. fileciteturn1file6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d58f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Parse datetimes & ensure numeric duration\n",
    "if 'df' in globals():\n",
    "    # Convert publish time\n",
    "    try:\n",
    "        df['Video Publish Time'] = pd.to_datetime(df['Video Publish Time'])\n",
    "    except Exception as e:\n",
    "        print('Publish time parse warning:', e)\n",
    "\n",
    "    # Ensure Video Duration is numeric (seconds) as in the PDF\n",
    "    if df['Video Duration'].dtype == object:\n",
    "        # try to coerce\n",
    "        df['Video Duration'] = pd.to_numeric(df['Video Duration'], errors='coerce')\n",
    "\n",
    "    print('Video Publish Time dtype:', df['Video Publish Time'].dtype)\n",
    "    print('Video Duration dtype:', df['Video Duration'].dtype)\n",
    "    display(df[['Video Duration','Video Publish Time']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781317a0",
   "metadata": {},
   "source": [
    "**Description:** Convert 'Video Publish Time' to datetime and ensure 'Video Duration' is numeric (seconds). The PDF shows these columns as present and important. fileciteturn1file6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee2cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Feature engineering\n",
    "if 'df' in globals():\n",
    "    # Revenue per View\n",
    "    df['Revenue_per_View'] = df['Estimated Revenue (USD)'] / df['Views'].replace(0, np.nan)\n",
    "    # Engagement Rate (Likes + Shares + Comments) / Views *100\n",
    "    for col in ['Likes','Shares','Comments']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    df['Engagement_Rate'] = (df['Likes'] + df['Shares'] + df['Comments']) / df['Views'].replace(0, np.nan) * 100\n",
    "    # Average View Percentage and Average View Duration exist in the dataset and are useful\n",
    "    # Extract publish hour, dayofweek\n",
    "    df['publish_hour'] = df['Video Publish Time'].dt.hour\n",
    "    df['publish_dayofweek'] = df['Video Publish Time'].dt.day_name()\n",
    "    display(df[['Revenue_per_View','Engagement_Rate','publish_hour','publish_dayofweek']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983761d",
   "metadata": {},
   "source": [
    "**Description:** Create `Revenue_per_View`, `Engagement_Rate`, and extract publish hour/day. These features often drive revenue and engagement as suggested in the PDF. fileciteturn1file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4173fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) EDA: distributions and correlation\n",
    "if 'df' in globals():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(df['Estimated Revenue (USD)'], bins=40, kde=True)\n",
    "    plt.title('Estimated Revenue Distribution')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.scatterplot(x='Views', y='Estimated Revenue (USD)', data=df, alpha=0.6)\n",
    "    plt.title('Revenue vs Views')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "\n",
    "    # Correlation heatmap for numeric features\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    corr = numeric_df.corr()\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation matrix (numeric)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c293a620",
   "metadata": {},
   "source": [
    "**Description:** Visualize revenue distribution, revenue vs views, and correlation matrix — all recommended in the PDF to identify strong predictors. fileciteturn1file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Prepare features & target\n",
    "if 'df' in globals():\n",
    "    # Choose a reasonable set of features (can expand later)\n",
    "    features = [\n",
    "        'Views','Subscribers','Likes','Shares','Comments',\n",
    "        'Average View Duration','Average View Percentage (%)',\n",
    "        'Video Duration','Impressions','Video Thumbnail CTR (%)',\n",
    "        'publish_hour','Engagement_Rate'\n",
    "    ]\n",
    "    # some column names may have slightly different spellings in your CSV; adapt as needed\n",
    "    present_features = [f for f in features if f in df.columns]\n",
    "    print('Using features:', present_features)\n",
    "    X = df[present_features].copy()\n",
    "    y = df['Estimated Revenue (USD)']\n",
    "\n",
    "    # Simple imputation for any missing numeric values\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imp = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_imp, y, test_size=0.2, random_state=42)\n",
    "    print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a248e8",
   "metadata": {},
   "source": [
    "**Description:** Select features for the regression target (Estimated Revenue) and impute missing numeric values with median. The PDF uses a similar set for modelling. fileciteturn1file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbbf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Train Random Forest Regressor\n",
    "if 'X_train' in globals():\n",
    "    model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'RMSE: {rmse:.4f}')\n",
    "    print(f'R2: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45421b5",
   "metadata": {},
   "source": [
    "**Description:** Train a baseline Random Forest regressor and evaluate using RMSE and R². The PDF demonstrates similar modeling steps. fileciteturn1file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Feature importance\n",
    "if 'model' in globals():\n",
    "    importances = model.feature_importances_\n",
    "    fi = pd.DataFrame({'feature': X_train.columns, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "    display(fi)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(x='importance', y='feature', data=fi.head(15))\n",
    "    plt.title('Top features by importance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9df9f",
   "metadata": {},
   "source": [
    "**Description:** Show which features the model finds most predictive for revenue. Use this to generate recommendations (e.g., increase thumbnails CTR or average view duration). fileciteturn1file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Save model and preprocessing objects\n",
    "if 'model' in globals():\n",
    "    joblib.dump(model, 'youtube_revenue_rf.pkl')\n",
    "    joblib.dump(imputer, 'youtube_imputer.pkl')\n",
    "    print('Saved model and imputer: youtube_revenue_rf.pkl, youtube_imputer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f03ee",
   "metadata": {},
   "source": [
    "**Description:** Persist trained model and imputer for later prediction/deployment. The PDF suggests exporting artifacts. fileciteturn1file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Predict helper example\n",
    "import numpy as _np\n",
    "\n",
    "def predict_sample(sample_dict):\n",
    "    # sample_dict must contain keys for present_features\n",
    "    s = pd.DataFrame([sample_dict])\n",
    "    # ensure columns\n",
    "    for c in X.columns:\n",
    "        if c not in s.columns:\n",
    "            s[c] = np.nan\n",
    "    s = s[X.columns]\n",
    "    s_imp = pd.DataFrame(imputer.transform(s), columns=s.columns)\n",
    "    model_loaded = joblib.load('youtube_revenue_rf.pkl')\n",
    "    pred = model_loaded.predict(s_imp)[0]\n",
    "    return pred\n",
    "\n",
    "# Example usage (uncomment and update values):\n",
    "# sample = {'Views':10000,'Subscribers':50,'Likes':200,'Shares':5,'Comments':10,'Average View Duration':120,'Average View Percentage (%)':50,'Video Duration':300,'Impressions':15000,'Video Thumbnail CTR (%)':3,'publish_hour':15,'Engagement_Rate':2}\n",
    "# print('Predicted Estimated Revenue (USD):', predict_sample(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445e59c",
   "metadata": {},
   "source": [
    "**Description:** Helper function to preprocess a single sample and return predicted revenue using saved artifacts. Update `sample` with values and run. fileciteturn1file2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4572e8",
   "metadata": {},
   "source": [
    "## Recommendations & Next steps\n",
    "\n",
    "- Perform hyperparameter tuning (GridSearchCV / RandomizedSearchCV) to improve model quality.\n",
    "- Add time-series analysis if you want to forecast revenue over time per channel.\n",
    "- Use advanced features: text features from title/description, thumbnail images (computer vision), or sequence models for temporal trends.\n",
    "- Create dashboards (Streamlit / Dash / Tableau) to present findings to creators.\n",
    "\n",
    "Refer to the PDF for the original project outline and dataset description. fileciteturn1file0"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
